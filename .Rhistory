######
ggplot(df, aes(x = DBH))+
geom_histogram(binwidth = 0.5,
color = "red",
fill = "#FF69B4",
alpha = .5)+
theme_bw()+
xlab("Stupid Trees")+
ylab("")+
facet_grid( .~ Plot)
##########
df$ba <- ((df$DBH/2)^2) * pi
head(df)
###
df %>%
group_by(Plot, Species) %>%
summarise(max(ba))
#####
# find out the unique plots we have
unique(df$Plot)
# make a list of data frames where each is a unique plot
big.boi <- split(df, df$Plot)
# Let's look at the total range
range(df$DBH)
# make the breaks that we want for DBH
breaks <- seq(0, 40, by = 5)
# loop through em all
x <- cut(big.boi[[i]][[4]], breaks, right = FALSE)
dbh.freq <- table(dbh.class)
y <- data.frame(dbh.freq)
dbh.freq <- table(dbh.class)
big.boi
range(df$DBH)
breaks <- seq(0, 40, by = 5)
x <- cut(big.boi[[i]][[4]], breaks, right = FALSE)
x <- cut(big.boi[[1]][[4]], breaks, right = FALSE)
dbh.freq <- table(dbh.class)
str(big.boi)
dbh.freq <- table(dbh.class)
x <- cut(big.boi[[i]][[4]], breaks, right = FALSE)
x
require(forestr)
citation(forestr)
require(forestr)
citation(forestr)
citation("forestr")
time_calib <- seq(from = ymd_hms("2016-07-03 12:00:00"), to = ymd_hms("2016-07-03 14:00:00"), by = "hour")
time_calib
times <- as_datetime(c("2016-07-03 12:20:00", "2016-07-03 12:30:00", "2016-07-03 12:40:00", "2016-07-03 12:50:00", "2016-07-03 13:00:00", "2016-07-03 13:10:00"))
vals <- c(2,1,1,1,9,1)
df <- data.frame(times, vals)
df
name_list <- colnames(df)
new_output <- data.frame(time_calib)
for(col in 2:ncol(df)){
new_output <- data.frame(new_output, (data.frame(approx(unlist(df[,1]), unlist(df[,col]), xout  = time_calib, method = "linear", ties = mean)))[,2])
}
colnames(new_output) <- name_list
new_output
new <- aggregate(list(temperature = df$vals),
list(hourofday = cut(df$times, "1 hour")),
mean)
new
time_calib <- seq(from = ymd_hms("2016-07-03 12:00:00"), to = ymd_hms("2016-07-03 14:00:00"), by = "hour")
time_calib
require(tidyverse)
require(lubridate)
time_calib <- seq(from = ymd_hms("2016-07-03 12:00:00"), to = ymd_hms("2016-07-03 14:00:00"), by = "hour")
time_calib
times <- as_datetime(c("2016-07-03 12:20:00", "2016-07-03 12:30:00", "2016-07-03 12:40:00", "2016-07-03 12:50:00", "2016-07-03 13:00:00", "2016-07-03 13:10:00"))
vals <- c(2,1,1,1,9,1)
df <- data.frame(times, vals)
df
name_list <- colnames(df)
new_output <- data.frame(time_calib)
for(col in 2:ncol(df)){
new_output <- data.frame(new_output, (data.frame(approx(unlist(df[,1]), unlist(df[,col]), xout  = time_calib, method = "linear", ties = mean)))[,2])
}
colnames(new_output) <- name_list
new_output
new <- aggregate(list(temperature = df$vals),
list(hourofday = cut(df$times, "1 hour")),
mean)
new
df
?approx
new_output
df
new
new_output
for(col in 2:ncol(df)){
new_output <- data.frame(new_output, (data.frame(approx(unlist(df[,1]), unlist(df[,col]), xout  = time_calib, method = "linear", ties = mean, na.rm = TRUE)))[,2])
}
colnames(new_output) <- name_list
new_output
new_output <- data.frame(time_calib)
new_output
new <- aggregate(list(temperature = df$vals),
list(hourofday = cut(df$times, "1 hour")),
mean)
new
df
average(c(2,1,0))
mean(c(2,1,0))
mean(c(1,1,1,9,1))
mean(c(1,1,1,9))
means <- aggregate(vals ~ times, df, mean)
head(means)
df$datehour <- hour(df$times)
df
library(data.table)
DT <- setDT(df)
DT
str(DT)
DT[,datepos := as.POSIXct(date,format = "%Y-%m-%d %H:%M:%OS")]
DT[,datediffindex := as.numeric((times - .SD[1,times])/60 )%/% 30]
DT
DT[,datepos := as.POSIXct(date,format = "%Y-%m-%d %H:%M:%OS")]
DT[,datediffindex := as.numeric((times - .SD[1,times])/60 )%/% 30]
str(df)
str(DT)
library(chron)
install.packages("chron")
data$time <- chron(times = df$times)
library(chron)
data$time <- chron(times = df$times)
data
df$time <- chron(times = df$times)
df
time_spent <- c(0, cumsum(diff(df$times)))
df$time <- chron(times = df$times)
?chron
DT[,datepos := as.POSIXct(date,format = "%Y-%m-%d %H:%M:%S")]
chron(times = df$times)
x <- read.table(text = "2012-07-22 12:12:00, 21
+ 2012-07-22 12:15:00, 22
+ 2012-07-22 12:18:00, 24
+ 2012-07-22 12:39:00, 21
+ 2012-07-22 12:45:00, 25
+ 2012-07-22 12:49:00, 26
+ 2012-07-22 12:53:00, 20
+ 2012-07-22 13:00:00, 18
+ 2012-07-22 13:06:00, 22", colClasses = c("POSIXct", "integer"), sep = ',')
x
x <- read.table(text = "2012-07-22 12:12:00, 21
+ 2012-07-22 12:15:00, 22
+ 2012-07-22 12:18:00, 24
+ 2012-07-22 12:39:00, 21
+ 2012-07-22 12:45:00, 25
+ 2012-07-22 12:49:00, 26
+ 2012-07-22 12:53:00, 20
+ 2012-07-22 13:00:00, 18
+ 2012-07-22 13:06:00, 22", colClasses = c("POSIXct", "integer"), sep = ',')
read.table(text = "2012-07-22 12:12:00, 21
+ 2012-07-22 12:15:00, 22
+ 2012-07-22 12:18:00, 24
+ 2012-07-22 12:39:00, 21
+ 2012-07-22 12:45:00, 25
+ 2012-07-22 12:49:00, 26
+ 2012-07-22 12:53:00, 20
+ 2012-07-22 13:00:00, 18
+ 2012-07-22 13:06:00, 22", colClasses = c("POSIXct", "integer"), sep = ',')
tmin <- trunc(min(df$times) units = "hour")
tmin <- trunc(min(df$times), units = "hour")
tmin
tMin <- trunc(min(df$times), units = "hour")
tMin <- tMin - (7.5 * 60)
tMin
> # create sequence for 'cut'
cSeq <- seq(tMin, max(df$times) + (7.5 * 60), by = '15 min')
cSeq
> # now split and average
cCut <- cut(df$times, cSeq)
cCut
df
> # compute means
tapply(df$vals, cCut, mean)
tMin <- trunc(min(df$times), units = "hour")
tMin <- tMin - (30 * 60)
> # create sequence for 'cut'
cSeq <- seq(tMin, max(df$times) + (730 * 60), by = '30 min')
cSeq
> # create sequence for 'cut'
cSeq <- seq(tMin, max(df$times) + (30 * 60), by = '30 min')
cSeq
install.packages("openAir")
install.packages("openair")
>
require(openair)
df$hours <- format(round(df$times, units="hours"), format="%H:%M")
df
str(df)
aggregate(data$value, by = list(data$hours), FUN = mean)
aggregate(data$value, by = data$hours, FUN = mean)
aggregate(data$value, by = as.numeric(data$hours), FUN = mean)
aggregate(data$value, by = as_datetime(data$hours), FUN = mean)
df$hours <- strptime(paste(df$times), format="%Y-%m-%d %H:%M")
str(df)
df
df$hours <- format(round(df$times, units="hours"), format="%H:%M")
df
aggregate(data$value, by = as_datetime(data$hours), FUN = mean)
aggregate(data$value, by = (data$hours), FUN = mean)
str(df)
aggregate(data$value, by = as.numeric(data$hours), FUN = mean)
df
df$hours2 <- gsub(".*:","", df$hours)
df
df$hours2 <- gsub("*:", "", df$hours)
df
df$hours2 <- gsub(":*.", "", df$hours)
df
df$hours2 <- gsub(":", "", df$hours)
df
df$hours2 <- as.numeric(gsub(":", "", df$hours))
str(df)
aggregate(data$value, by = as.numeric(data$hours), FUN = mean)
aggregate(data$value, by = df$hours2, FUN = mean)
aggregate(df$value, by = df$hours, FUN = mean)
aggregate(df$value, by = df$hours2, FUN = mean)
df
aggregate(df$vals, by = df$hours, FUN = mean)
aggregate(df$vals, by = list(df$hours), FUN = mean)
mean(c(1,1,1,9,1))
require(tidyverse)
require(lubridate)
time_calib <- seq(from = ymd_hms("2016-07-03 12:00:00"), to = ymd_hms("2016-07-03 14:00:00"), by = "hour")
time_calib
times <- as_datetime(c("2016-07-03 12:20:00", "2016-07-03 12:30:00", "2016-07-03 12:40:00", "2016-07-03 12:50:00", "2016-07-03 13:00:00", "2016-07-03 13:10:00"))
vals <- c(2,1,1,1,9,1)
df <- data.frame(times, vals)
df
df$hours <- format(round(df$times, units="hours"), format="%H:%M")
aggregate(df$vals, by = list(df$hours), FUN = mean)
#test
#dependencies
require(tidyverse)
require(ggplot2)
#import data
df <- read.csv("./data/laura.csv")
#structure of data frame
str(df)
df
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
head(df)
df %>%
group_by(plot)
missing lines.
require(plyr)
require(dplyr)
require(tidyverse)
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
str(df)
head(df)
df %>%
group_by(Plot) %>%
summarise_all(mean)
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(Plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
df2
# pcl processing script
#this script, thanks in part to the indomitable Ben Bond-Lamberty, error checks which files have missing lines.
require(plyr)
require(dplyr)
require(tidyverse)
require(forestr)
setwd("./data/pcl")
files <- list.files(pattern = "*.CSV", full.names = TRUE)
for(i in seq_along(files)) {
filedata <- readLines(files[i])
lines_to_skip <- min(which(filedata != "")) - 1
cat(i, files[i], lines_to_skip, "\n")
x <- read.csv(files[i], skip = lines_to_skip)
}
setwd("c:/github/reu_hickey_2018/")
####
data_dir <- ("./data/pcl")
process_multi_pcl(data_dir, marker.spacing = 10, max.vai = 8)
output_directory <- "./output/output"
#
library(dplyr)
library(readr)
df <- list.files(path = output_directory, full.names = TRUE) %>%
lapply(read_csv) %>%
bind_rows
df <- data.frame(df)
write.csv(df, "hickey_reu.CSV")
head(df)
df %>%
group_by(Plot) %>%
summarise_all(mean) -> df2
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
data_dir <- ("./data/kreider")
process_multi_pcl(data_dir, marker.spacing = 10, max.vai = 8)
# collating data output
output_directory <- "./output/output"
library(dplyr)
library(readr)
df <- list.files(path = output_directory, full.names = TRUE) %>%
lapply(read_csv) %>%
bind_rows
df <- data.frame(df)
write.csv(df, "hickey_reu.CSV")
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
df2
head(df2)
require(ggplot2)
x %>%
group_by(plot) %>%
summarise_all(mean) -> df
df <- data.frame(df)
x <- read.csv("hickey_reu_annotated.csv")
x %>%
group_by(plot) %>%
summarise_all(mean) -> df
df <- data.frame(df)
plot(df$age, df$rugosity)
ggplot(df, aes(x = age, y = rugosity, color = status))+
geom_point()
x11()
ggplot(df, aes(x = age, y = rugosity, color = status))+
geom_point()
head(df)
head(s)
head(x)
x11()
ggplot(x, aes(x = age, y = rugosity, color = status))+
geom_point()
str(x)
x %>%
group_by(plot, status) %>%
summarise_all(mean) -> df
df <- data.frame(df)
plot(df$age, df$rugosity)
x11()
ggplot(df, aes(x = age, y = rugosity, color = status))+
geom_point()
df %>%
filter(status == "planted") -> df.p
df.p
str(df)
#laura script
require(ggplot2)
x <- read.csv("hickey_reu_annotated.csv")
x %>%
group_by(plot, status) %>%
summarise_all(mean) -> df
df <- data.frame(df)
plot(df$age, df$rugosity)
x11()
ggplot(df, aes(x = age, y = rugosity, color = status))+
geom_point()
# planted
df %>%
filter(status == "planted") -> df.p
str(df.p)
M <- cor(df[, c(3, 5:32)])
corrplot(M, method = "circle")
require(corrplot)
corrplot(M, method = "circle")
x11()
corrplot(M, method = "circle")
reu <- read.csv("REU16_plot_summary.csv")
list.files()
reu <- read.csv("REU18_plot_summary.csv")
head(reu)
df.pp <- merge(df.p, reu)
head(df.pp)
View(df.pp)
head(reu)
df.pp <- merge(df.p, reu, by = "plot")
View(df.pp)
x11()
ggplot(df.pp, aes(x = annual_nppw, y = rugosity))+
geom_point()
x11()
ggplot(df.pp, aes(x = annual_nppw, y = rumple))+
geom_point()
x11()
ggplot(df.pp, aes(y = annual_nppw, x = enl))+
geom_point()
x11()
ggplot(df.pp, aes(y = annual_nppw, x = mean.max.ht))+
geom_point()
x11()
ggplot(df.pp, aes(y = age, x = mean.max.ht))+
geom_point()
head(df.pp)
x11()
ggplot(df.pp, aes(y = age.x, x = mean.max.ht))+
geom_point()
3.59/0.08
3.59/0.92
3.59/1602
3.59*0.92
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
#this script, thanks in part to the indomitable Ben Bond-Lamberty, error checks which files have missing lines.
require(plyr)
require(dplyr)
require(tidyverse)
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
head(df2)
str(df2)
dim(df2)
unique(df2$plot)
df <- read.csv("hickey_reu_annotated.csv")
df %>%
group_by(plot) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
dim(df2)
require(plyr)
require(dplyr)
require(tidyverse)
require(ggplot2)
head(df2)
ggplot(df2, aes(x = age, y = rugosity, color = status))+
geom_point()
df %>%
group_by(plot) %>%
summarise_all(mean, drop == "FALSE") -> df2
?summarize_all
dim(df)
str(df\)
str(df)
df %>%
group_by(plot) %>%
summarise_at(c[6:33,], mean) -> df2
df %>%
group_by(plot) %>%
summarise_at(c[,6:33], mean) -> df2
df %>%
group_by(plot) %>%
summarise_at(vars(c[,6:33]), mean) -> df2
df %>%
group_by(plot, stand, status) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
head(df2)
ggplot(df2, aes(x = age, y = rugosity, color = status))+
geom_point()
df %>%
group_by(stand, status) %>%
summarise_all(mean) -> df2
df2 <- data.frame(df2)
ggplot(df2, aes(x = age, y = rugosity, color = status))+
geom_point()
ggplot(df2, aes(x = age, y = rugosity, color = status))+
geom_point()+
geom_smooth(method = "lm")
lm.rugosity <- lm(rugosity ~ age, data = df2)
lm.rugosity
summary(lm.rugosity)
require(randomForest)
laura.fit <- randomForest(as.factor(status) ~  c[6:33],
data = df2,
importance = TRUE,
ntree = 2000)
# View the forest results.
laura.fit <- randomForest(as.factor(status) ~  c[6:33, ],
data = df2,
importance = TRUE,
ntree = 2000)
# View the forest results.
laura.fit <- randomForest(as.factor(status) ~  mean.height +	height.2 + mean.height.var +	mean.height.rms +	mode.el +	max.el + mode.2 + max.can.ht	+ mean.max.ht +	mean.vai +	mean.peak.vai +	deep.gap.fraction + porosity	+	rugosity +
top.rugosity + sky.fraction	+ rumple +	clumping.index +	enl,
data = df2,
importance = TRUE,
ntree = 2000)
laura.fit
print(importance((laura.fit)) )
varImpPlot(laura.fit)
ggplot(df2, aes(x = age, y = clumping.index, color = status))+
geom_point()+
geom_smooth(method = "lm")
laura.fit <- randomForest(as.factor(status * age) ~  mean.height +	height.2 + mean.height.var +	mean.height.rms +	mode.el +	max.el + mode.2 + max.can.ht	+ mean.max.ht +	mean.vai +	mean.peak.vai +	deep.gap.fraction + porosity	+	rugosity +
top.rugosity + sky.fraction	+ rumple +	clumping.index +	enl,
data = df2,
importance = TRUE,
ntree = 2000)
#model fit
laura.fit
laura.fit <- randomForest(status * as.factor(age) ~  mean.height +	height.2 + mean.height.var +	mean.height.rms +	mode.el +	max.el + mode.2 + max.can.ht	+ mean.max.ht +	mean.vai +	mean.peak.vai +	deep.gap.fraction + porosity	+	rugosity +
top.rugosity + sky.fraction	+ rumple +	clumping.index +	enl,
data = df2,
importance = TRUE,
ntree = 2000)
#model fit
laura.fit
